{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T11:35:38.657600Z",
     "iopub.status.busy": "2021-01-24T11:35:38.656864Z",
     "iopub.status.idle": "2021-01-24T11:35:43.980795Z",
     "shell.execute_reply": "2021-01-24T11:35:43.979212Z"
    },
    "papermill": {
     "duration": 5.342334,
     "end_time": "2021-01-24T11:35:43.981030",
     "exception": false,
     "start_time": "2021-01-24T11:35:38.638696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import xgboost as xgb\n",
    "import optuna   \n",
    "import cudf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T11:35:44.021882Z",
     "iopub.status.busy": "2021-01-24T11:35:44.021071Z",
     "iopub.status.idle": "2021-01-24T11:38:29.697953Z",
     "shell.execute_reply": "2021-01-24T11:38:29.698978Z"
    },
    "papermill": {
     "duration": 165.69484,
     "end_time": "2021-01-24T11:38:29.699185",
     "exception": false,
     "start_time": "2021-01-24T11:35:44.004345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "train = pd.read_csv('../input/jane-street-market-prediction/train.csv')\n",
    "train = train.query('date > 85').reset_index(drop = True)  #去掉前85天\n",
    "train = train.astype({c: np.float32 for c in train.select_dtypes(include='float64').columns}) #float64换成float32limit memory use\n",
    "#tree和neural network的区别是tree里不要人为加入bias 所以fillna通常用很大的极限值 这样就把有missing的分到一个单独的brunch上\n",
    "train.fillna(-9999,inplace=True)\n",
    "train = train.query('weight > 0').reset_index(drop = True) #drop掉weight为零的\n",
    "features = [c for c in train.columns if 'feature' in c]\n",
    "X = train[features].values\n",
    "y = (train['resp'] > 0).astype('int') #tree只能做single target 现在选的是resp这个指标 大于0为1 小于等于0为0 可调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T11:38:29.749266Z",
     "iopub.status.busy": "2021-01-24T11:38:29.748318Z",
     "iopub.status.idle": "2021-01-24T11:38:29.773642Z",
     "shell.execute_reply": "2021-01-24T11:38:29.774344Z"
    },
    "papermill": {
     "duration": 0.0563,
     "end_time": "2021-01-24T11:38:29.774495",
     "exception": false,
     "start_time": "2021-01-24T11:38:29.718195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\n",
    "from sklearn.utils.validation import _deprecate_positional_args\n",
    "\n",
    "# modified code for group gaps; source\n",
    "# https://github.com/getgaurav2/scikit-learn/blob/d4a3af5cc9da3a76f0266932644b884c99724c57/sklearn/model_selection/_split.py#L2243\n",
    "class PurgedGroupTimeSeriesSplit(_BaseKFold):\n",
    "    \"\"\"Time Series cross-validator variant with non-overlapping groups.\n",
    "    Allows for a gap in groups to avoid potentially leaking info from\n",
    "    train into test if the model has windowed or lag features.\n",
    "    Provides train/test indices to split time series data samples\n",
    "    that are observed at fixed time intervals according to a\n",
    "    third-party provided group.\n",
    "    In each split, test indices must be higher than before, and thus shuffling\n",
    "    in cross validator is inappropriate.\n",
    "    This cross-validation object is a variation of :class:`KFold`.\n",
    "    In the kth split, it returns first k folds as train set and the\n",
    "    (k+1)th fold as test set.\n",
    "    The same group will not appear in two different folds (the number of\n",
    "    distinct groups has to be at least equal to the number of folds).\n",
    "    Note that unlike standard cross-validation methods, successive\n",
    "    training sets are supersets of those that come before them.\n",
    "    Read more in the :ref:`User Guide <cross_validation>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default=5\n",
    "        Number of splits. Must be at least 2.\n",
    "    max_train_group_size : int, default=Inf\n",
    "        Maximum group size for a single training set.\n",
    "    group_gap : int, default=None\n",
    "        Gap between train and test\n",
    "    max_test_group_size : int, default=Inf\n",
    "        We discard this number of groups from the end of each train split\n",
    "    \"\"\"\n",
    "\n",
    "    @_deprecate_positional_args\n",
    "    def __init__(self,\n",
    "                 n_splits=5,\n",
    "                 *,\n",
    "                 max_train_group_size=np.inf,\n",
    "                 max_test_group_size=np.inf,\n",
    "                 group_gap=None,\n",
    "                 verbose=False\n",
    "                 ):\n",
    "        super().__init__(n_splits, shuffle=False, random_state=None)\n",
    "        self.max_train_group_size = max_train_group_size\n",
    "        self.group_gap = group_gap\n",
    "        self.max_test_group_size = max_test_group_size\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Always ignored, exists for compatibility.\n",
    "        groups : array-like of shape (n_samples,)\n",
    "            Group labels for the samples used while splitting the dataset into\n",
    "            train/test set.\n",
    "        Yields\n",
    "        ------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        \"\"\"\n",
    "        if groups is None:\n",
    "            raise ValueError(\n",
    "                \"The 'groups' parameter should not be None\")\n",
    "        X, y, groups = indexable(X, y, groups)\n",
    "        n_samples = _num_samples(X)\n",
    "        n_splits = self.n_splits\n",
    "        group_gap = self.group_gap\n",
    "        max_test_group_size = self.max_test_group_size\n",
    "        max_train_group_size = self.max_train_group_size\n",
    "        n_folds = n_splits + 1\n",
    "        group_dict = {}\n",
    "        u, ind = np.unique(groups, return_index=True)\n",
    "        unique_groups = u[np.argsort(ind)]\n",
    "        n_samples = _num_samples(X)\n",
    "        n_groups = _num_samples(unique_groups)\n",
    "        for idx in np.arange(n_samples):\n",
    "            if (groups[idx] in group_dict):\n",
    "                group_dict[groups[idx]].append(idx)\n",
    "            else:\n",
    "                group_dict[groups[idx]] = [idx]\n",
    "        if n_folds > n_groups:\n",
    "            raise ValueError(\n",
    "                (\"Cannot have number of folds={0} greater than\"\n",
    "                 \" the number of groups={1}\").format(n_folds,\n",
    "                                                     n_groups))\n",
    "\n",
    "        group_test_size = min(n_groups // n_folds, max_test_group_size)\n",
    "        group_test_starts = range(n_groups - n_splits * group_test_size,\n",
    "                                  n_groups, group_test_size)\n",
    "        for group_test_start in group_test_starts:\n",
    "            train_array = []\n",
    "            test_array = []\n",
    "\n",
    "            group_st = max(0, group_test_start - group_gap - max_train_group_size)\n",
    "            for train_group_idx in unique_groups[group_st:(group_test_start - group_gap)]:\n",
    "                train_array_tmp = group_dict[train_group_idx]\n",
    "                \n",
    "                train_array = np.sort(np.unique(\n",
    "                                      np.concatenate((train_array,\n",
    "                                                      train_array_tmp)),\n",
    "                                      axis=None), axis=None)\n",
    "\n",
    "            train_end = train_array.size\n",
    " \n",
    "            for test_group_idx in unique_groups[group_test_start:\n",
    "                                                group_test_start +\n",
    "                                                group_test_size]:\n",
    "                test_array_tmp = group_dict[test_group_idx]\n",
    "                test_array = np.sort(np.unique(\n",
    "                                              np.concatenate((test_array,\n",
    "                                                              test_array_tmp)),\n",
    "                                     axis=None), axis=None)\n",
    "\n",
    "            test_array  = test_array[group_gap:]\n",
    "            \n",
    "            \n",
    "            if self.verbose > 0:\n",
    "                    pass\n",
    "                    \n",
    "            yield [int(i) for i in train_array], [int(i) for i in test_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T11:38:29.822226Z",
     "iopub.status.busy": "2021-01-24T11:38:29.821105Z",
     "iopub.status.idle": "2021-01-24T11:38:54.127896Z",
     "shell.execute_reply": "2021-01-24T11:38:54.127333Z"
    },
    "papermill": {
     "duration": 24.335386,
     "end_time": "2021-01-24T11:38:54.128031",
     "exception": false,
     "start_time": "2021-01-24T11:38:29.792645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FOLDS=5\n",
    "import gc\n",
    "gkf = PurgedGroupTimeSeriesSplit(n_splits = FOLDS, group_gap=20)\n",
    "splits = list(gkf.split(y, groups=train['date'].values))\n",
    "del train\n",
    "gc.collect()\n",
    "for fold, (train_indices, test_indices) in enumerate(splits): #分5个folds 但后一个会覆盖前一个 最后只剩第5个 这样做因为time-series split最后的auc最大 因为最后的tree和validation数据多 见群里分析图\n",
    "    X_train, X_valid = X[train_indices], X[test_indices]\n",
    "    y_train, y_valid = y[train_indices], y[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T11:38:54.162168Z",
     "iopub.status.busy": "2021-01-24T11:38:54.161297Z",
     "iopub.status.idle": "2021-01-24T11:39:00.510922Z",
     "shell.execute_reply": "2021-01-24T11:39:00.509762Z"
    },
    "papermill": {
     "duration": 6.36895,
     "end_time": "2021-01-24T11:39:00.511051",
     "exception": false,
     "start_time": "2021-01-24T11:38:54.142101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Created the Xgboost specific DMatrix data format from the numpy array to optimise memory consumption\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dvalid = xgb.DMatrix(X_valid, label=y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T11:39:00.549327Z",
     "iopub.status.busy": "2021-01-24T11:39:00.547489Z",
     "iopub.status.idle": "2021-01-24T11:39:00.550029Z",
     "shell.execute_reply": "2021-01-24T11:39:00.550484Z"
    },
    "papermill": {
     "duration": 0.025557,
     "end_time": "2021-01-24T11:39:00.550597",
     "exception": false,
     "start_time": "2021-01-24T11:39:00.525040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "# params specifies the XGBoost hyperparameters to be tuned\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 400, 600), #一共几个树叶：400-600\n",
    "        'max_depth': trial.suggest_int('max_depth', 10, 20), #每个树的深度：10-20\n",
    "        'learning_rate': trial.suggest_uniform('learning_rate', 0.01, .1), #每个树update的幅度\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.50, 1), \n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.50, 1),\n",
    "        'gamma': trial.suggest_int('gamma', 0, 10),\n",
    "        'tree_method': 'gpu_hist',  \n",
    "        'objective': 'binary:logistic'\n",
    "    }\n",
    "    \n",
    "    bst = xgb.train(params, dtrain) #用贝叶森选的parameter在trian上建model\n",
    "    preds = bst.predict(dvalid) #在tree上做预测 预测结果为0-1的probability\n",
    "    pred_labels = np.rint(preds) #把预测结果转换成0和1 \n",
    "# trials will be evaluated based on their accuracy on the test set\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_valid, pred_labels) #预测结果与真实值比较\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T11:39:00.582521Z",
     "iopub.status.busy": "2021-01-24T11:39:00.581675Z",
     "iopub.status.idle": "2021-01-24T11:39:21.786672Z",
     "shell.execute_reply": "2021-01-24T11:39:21.787636Z"
    },
    "papermill": {
     "duration": 21.223713,
     "end_time": "2021-01-24T11:39:21.787795",
     "exception": false,
     "start_time": "2021-01-24T11:39:00.564082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-24 11:39:00,579]\u001b[0m A new study created in memory with name: no-name-389db1e8-2d82-427a-941b-8baa8a9b880a\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:39:00] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-24 11:39:03,419]\u001b[0m Trial 0 finished with value: 0.5193769932792303 and parameters: {'n_estimators': 448, 'max_depth': 10, 'learning_rate': 0.09173534908043456, 'subsample': 0.9875714129412798, 'colsample_bytree': 0.5373008049241719, 'gamma': 6}. Best is trial 0 with value: 0.5193769932792303.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:39:03] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-24 11:39:07,953]\u001b[0m Trial 1 finished with value: 0.5146363075112039 and parameters: {'n_estimators': 419, 'max_depth': 15, 'learning_rate': 0.08438579306565921, 'subsample': 0.8849743693191983, 'colsample_bytree': 0.6179600233449092, 'gamma': 6}. Best is trial 1 with value: 0.5146363075112039.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:39:07] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-24 11:39:12,591]\u001b[0m Trial 2 finished with value: 0.5134847239238292 and parameters: {'n_estimators': 549, 'max_depth': 15, 'learning_rate': 0.08393104415003413, 'subsample': 0.5197202552686686, 'colsample_bytree': 0.6010766309189856, 'gamma': 4}. Best is trial 2 with value: 0.5134847239238292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:39:12] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-24 11:39:19,553]\u001b[0m Trial 3 finished with value: 0.5161941441974582 and parameters: {'n_estimators': 540, 'max_depth': 17, 'learning_rate': 0.05564343345380777, 'subsample': 0.9572176444592828, 'colsample_bytree': 0.5062623208298063, 'gamma': 7}. Best is trial 2 with value: 0.5134847239238292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:39:19] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-24 11:39:21,778]\u001b[0m Trial 4 finished with value: 0.5163508875190731 and parameters: {'n_estimators': 452, 'max_depth': 12, 'learning_rate': 0.043597142177279655, 'subsample': 0.5398298129783408, 'colsample_bytree': 0.8965255891090069, 'gamma': 4}. Best is trial 2 with value: 0.5134847239238292.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize') #用optuna这个包做贝叶森 跑得更快\n",
    "study.optimize(objective,n_trials=20) #trial越多学的越多 跑的时间越长\n",
    "#You can increase n_trials parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T11:39:21.839257Z",
     "iopub.status.busy": "2021-01-24T11:39:21.838494Z",
     "iopub.status.idle": "2021-01-24T11:39:21.843063Z",
     "shell.execute_reply": "2021-01-24T11:39:21.839877Z"
    },
    "papermill": {
     "duration": 0.033436,
     "end_time": "2021-01-24T11:39:21.843236",
     "exception": false,
     "start_time": "2021-01-24T11:39:21.809800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: score 0.5134847239238292, params {'n_estimators': 549, 'max_depth': 15, 'learning_rate': 0.08393104415003413, 'subsample': 0.5197202552686686, 'colsample_bytree': 0.6010766309189856, 'gamma': 4}\n"
     ]
    }
   ],
   "source": [
    "print('Best trial: score {}, params {}'.format(study.best_trial.value, study.best_trial.params))\n",
    "#希望score是在0.52-0.53\n",
    "#inference要用到params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "papermill": {
   "duration": 543.941343,
   "end_time": "2021-01-24T11:44:38.333688",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-24T11:35:34.392345",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
